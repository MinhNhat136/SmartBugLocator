{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d78a8b75eaea1f5",
   "metadata": {},
   "source": "## PREPROCESSING DATA"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:00.981897Z",
     "start_time": "2025-04-10T16:49:56.735349Z"
    }
   },
   "source": [
    "from preprocessing import Parser, ReportPreprocessor, SrcPreprocessor\n",
    "from datasets import DATASETS\n",
    "import os\n",
    "\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "340c1372-80a5-4286-b398-6300e04e7e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:02.020682Z",
     "start_time": "2025-04-10T16:50:01.003516Z"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nhatm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\nhatm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "017deb6b-c635-4cf6-a8b3-bbc1c77feb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T05:10:10.457529Z",
     "start_time": "2025-04-08T05:10:10.454014Z"
    }
   },
   "source": [
    "def preprocessing_data(dataset):\n",
    "    parser = Parser(dataset)\n",
    "    bug_reports = parser.report_parser()\n",
    "    src_files = parser.src_parser()\n",
    "\n",
    "    os.makedirs(f'outputs/{dataset.name}', exist_ok=True)\n",
    "\n",
    "    SrcPreprocessor(src_files).preprocess_and_export(dataset.name)\n",
    "    ReportPreprocessor(bug_reports).preprocess_and_export(dataset.name)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T05:28:22.042474Z",
     "start_time": "2025-04-08T05:10:13.411752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for DATASET in DATASETS:\n",
    "    preprocessing_data(DATASET)"
   ],
   "id": "5bf5275c44d766ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## INDEXING SOURCE CODE FILES\n",
   "id": "fdcd0c9ad3294b33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:02.084487Z",
     "start_time": "2025-04-10T16:50:02.081913Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_name = 'tomcat'",
   "id": "808aea35aed54545",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ff7344416bf756c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:03.990607Z",
     "start_time": "2025-04-10T16:50:02.087328Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "be114cc0a930d52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:03.998406Z",
     "start_time": "2025-04-10T16:50:03.994351Z"
    }
   },
   "source": [
    "def prepare_dataframe_src_code(name):\n",
    "    return pd.read_csv(f\"outputs/{name}/source_code_data.csv\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:04.006296Z",
     "start_time": "2025-04-10T16:50:04.002809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_and_fetch_src_code_infor(data_src_code):\n",
    "    def extract_stemmed(column, field = 'stemmed'):\n",
    "        return column.apply(ast.literal_eval).apply(lambda x: x[field])\n",
    "\n",
    "    stem_columns = ['pos_tagged_comments']\n",
    "    for col in stem_columns:\n",
    "        data_src_code[col] = extract_stemmed(data_src_code[col])\n",
    "\n",
    "    un_stem_columns = ['file_name', 'class_names', 'method_names']\n",
    "    for col in un_stem_columns:\n",
    "        data_src_code[col] = extract_stemmed(data_src_code[col], 'unstemmed')\n",
    "\n",
    "    data_src_code['natural_language'] = data_src_code['pos_tagged_comments']\n",
    "    data_src_code['code_entities'] = data_src_code.apply(lambda row: row['file_name'] + row['class_names']+ row['method_names'], axis=1)\n",
    "\n",
    "    return data_src_code[['key', 'natural_language', 'code_entities', 'total_lines']]\n"
   ],
   "id": "384cb968119fadaf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "289d819f926efbd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:04.024837Z",
     "start_time": "2025-04-10T16:50:04.016257Z"
    }
   },
   "source": [
    "def build_inverted_index(dataset, column_data_string):\n",
    "    inverted_index = defaultdict(set)\n",
    "    for data in dataset.iterrows():\n",
    "        for content in data[1][column_data_string]:\n",
    "            inverted_index[content].add(data[1]['key'])\n",
    "    return inverted_index"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:05.408492Z",
     "start_time": "2025-04-10T16:50:04.038140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_dataset = fix_and_fetch_src_code_infor(prepare_dataframe_src_code(dataset_name))\n",
    "inverted_index_natural_language_src_codes = build_inverted_index(df_dataset, 'natural_language')\n",
    "inverted_index_code_entities_src_codes = build_inverted_index(df_dataset, 'code_entities')"
   ],
   "id": "d6cfe3145242a041",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "29a078b9603f82dc",
   "metadata": {},
   "source": [
    "## BUILD VSM"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae7e9d6e0c7047d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:05.455028Z",
     "start_time": "2025-04-10T16:50:05.451161Z"
    }
   },
   "source": [
    "import math"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "322f41dfda205c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:05.498963Z",
     "start_time": "2025-04-10T16:50:05.494488Z"
    }
   },
   "source": [
    "def compute_ltc(documents, inverted_index, field):\n",
    "    tf_idf = defaultdict(lambda: defaultdict(float))\n",
    "    total_documents = len(documents)\n",
    "\n",
    "    for data in documents.iterrows():\n",
    "        doc_id = data[1].key\n",
    "        field_content = data[1][field]\n",
    "\n",
    "        content_frequency = defaultdict(int)\n",
    "\n",
    "        if isinstance(field_content, list) and len(field_content) > 0:\n",
    "            for content in field_content:\n",
    "                content_frequency[content] += 1\n",
    "\n",
    "            for content, count in content_frequency.items():\n",
    "                tf = 1 + math.log(count, 10)\n",
    "                df = len(inverted_index.get(content, []))\n",
    "                idf = math.log(total_documents / df, 10) if df != 0 else 0\n",
    "\n",
    "                tf_idf[doc_id][content] = tf * idf\n",
    "        else:\n",
    "            tf_idf[doc_id] = {}\n",
    "\n",
    "    for doc_id in tf_idf:\n",
    "        norm = math.sqrt(sum(weight ** 2 for weight in tf_idf[doc_id].values()))\n",
    "        if norm > 0:\n",
    "            for content in tf_idf[doc_id]:\n",
    "                tf_idf[doc_id][content] /= norm\n",
    "\n",
    "    return tf_idf\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "caefb66e5980cba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:05.681366Z",
     "start_time": "2025-04-10T16:50:05.538596Z"
    }
   },
   "source": [
    "natural_lang_vsm_src_codes = compute_ltc(df_dataset, inverted_index_natural_language_src_codes, 'natural_language')\n",
    "code_entities_vsm_src_codes = compute_ltc(df_dataset, inverted_index_code_entities_src_codes, 'code_entities')"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "6bd66b7a09944bd2",
   "metadata": {},
   "source": [
    "## CALCULATE COEFFICIENT FILE SIZE"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:05.890154Z",
     "start_time": "2025-04-10T16:50:05.885742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_max_size_dataset = (df_dataset.total_lines.min(), df_dataset.total_lines.max())\n",
    "min_max_size_dataset"
   ],
   "id": "97f946a86ea261eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 138)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a3a53ec93e31827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:05.978523Z",
     "start_time": "2025-04-10T16:50:05.975922Z"
    }
   },
   "source": [
    "def calculate_coefficient_size(size, size_data):\n",
    "    min_size, max_size = size_data\n",
    "    value_standardization = (size - min_size) / (max_size - min_size)\n",
    "    return 1/(1 + math.exp(-value_standardization))"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:07.169315Z",
     "start_time": "2025-04-10T16:50:07.163154Z"
    }
   },
   "cell_type": "code",
   "source": "df_dataset['coefficient_size'] = df_dataset['total_lines'].apply(lambda x: calculate_coefficient_size(x, min_max_size_dataset))",
   "id": "c4b9abb4577c65ad",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "27ec623e3368f0d",
   "metadata": {},
   "source": [
    "## HANDLE REPORT DATA"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:08.684302Z",
     "start_time": "2025-04-10T16:50:08.680511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_dataframe_bug_reports(name):\n",
    "    return pd.read_csv(f\"outputs/{name}/bug_reports.csv\")"
   ],
   "id": "e0548480f127ac3d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:09.702210Z",
     "start_time": "2025-04-10T16:50:09.697975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_and_fetch_bug_report(report):\n",
    "    report.pos_tagged_description = report.pos_tagged_description.apply(ast.literal_eval)\n",
    "    report.pos_tagged_description = report.pos_tagged_description.apply(lambda x: x['unstemmed'])\n",
    "\n",
    "    report.pos_tagged_summary = report.pos_tagged_summary.apply(ast.literal_eval)\n",
    "    report.pos_tagged_summary = report.pos_tagged_summary.apply(lambda x: x['stemmed'])\n",
    "\n",
    "    report['fixed_files'] = report['fixed_files'].apply(lambda x: [f for f in x.split() if f != '.'] if isinstance(x, str) else x)\n",
    "\n",
    "    report['natural_language'] = report.pos_tagged_summary\n",
    "    report['code_entities'] = report.pos_tagged_description\n",
    "\n",
    "    return report[['key', 'natural_language', 'code_entities', 'report_time', 'fixed_files']]"
   ],
   "id": "32e07b0c666bd3af",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "14bc28e2d90c1b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:11.013326Z",
     "start_time": "2025-04-10T16:50:11.009346Z"
    }
   },
   "source": [
    "def compute_lnc(query, field):\n",
    "    tf_idf = defaultdict(float)\n",
    "\n",
    "    term_freq = defaultdict(int)\n",
    "    for term in query[field]:\n",
    "        term_freq[term] += 1\n",
    "\n",
    "    for term, freq in term_freq.items():\n",
    "        tf = 1 + math.log10(freq)\n",
    "        tf_idf[term] = tf * 1\n",
    "\n",
    "    norm = math.sqrt(sum(weight ** 2 for weight in tf_idf.values()))\n",
    "    if norm > 0:\n",
    "        for term in tf_idf:\n",
    "            tf_idf[term] /= norm\n",
    "\n",
    "    return tf_idf"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:12.223162Z",
     "start_time": "2025-04-10T16:50:12.216176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_bnc(query, field):\n",
    "    tf_idf = defaultdict(float)\n",
    "\n",
    "    unique_terms = set(query[field])\n",
    "\n",
    "    for term in unique_terms:\n",
    "        tf = 1\n",
    "        tf_idf[term] = tf * 1\n",
    "\n",
    "    norm = math.sqrt(sum(weight ** 2 for weight in tf_idf.values()))\n",
    "    if norm > 0:\n",
    "        for term in tf_idf:\n",
    "            tf_idf[term] /= norm\n",
    "\n",
    "    return tf_idf\n"
   ],
   "id": "57a4f63e281abc2f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:14.014171Z",
     "start_time": "2025-04-10T16:50:13.825819Z"
    }
   },
   "cell_type": "code",
   "source": "bug_report_dataset = fix_and_fetch_bug_report(prepare_dataframe_bug_reports(dataset_name))",
   "id": "ac8a2055a1a60292",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CALCULATE rVSM",
   "id": "4300300ecb1d88bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:15.202746Z",
     "start_time": "2025-04-10T16:50:15.195707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_indexing_score(query, vsm, compute_query, field):\n",
    "    query_vec = compute_query(query, field)\n",
    "    scores = {}\n",
    "\n",
    "    for directory, doc_vec in vsm.items():\n",
    "        dot_product = 0.0\n",
    "        for term in query_vec:\n",
    "            dot_product += query_vec[term] * doc_vec.get(term, 0.0)\n",
    "\n",
    "        scores[directory] = dot_product * df_dataset.loc[df_dataset['key'] == directory, 'coefficient_size'].iloc[0]\n",
    "\n",
    "    return scores"
   ],
   "id": "829b5c0af3396404",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T16:50:16.365522Z",
     "start_time": "2025-04-10T16:50:16.361302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_rank_files_indexing(query, coefficient):\n",
    "    scores_indexing = defaultdict(float)\n",
    "    scores_nl = compute_indexing_score(query, natural_lang_vsm_src_codes, compute_lnc,'natural_language')\n",
    "    scores_ce = compute_indexing_score(query, code_entities_vsm_src_codes, compute_lnc,'code_entities')\n",
    "\n",
    "    for score_key in scores_ce:\n",
    "        scores_indexing[score_key] = coefficient * scores_nl[score_key] + (1 - coefficient)* scores_ce[score_key]\n",
    "\n",
    "    return scores_indexing"
   ],
   "id": "b15c7f93376f757e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GET PREVIOUS BUG REPORT",
   "id": "79a11c4267d84ccd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:07:37.211664Z",
     "start_time": "2025-04-10T13:07:37.207495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_previous_bug_fixed_report(df, current_bug_id):\n",
    "    df_sorted = df.sort_values(by='report_time')\n",
    "    previous_bugs = df_sorted[df_sorted['report_time'] < df_sorted[df_sorted['key'] == current_bug_id]['report_time'].iloc[0]]\n",
    "    return previous_bugs\n",
    "\n",
    "def calculate_bug_query_similarity(df, current_bug_id):\n",
    "    previous_bugs = get_previous_bug_fixed_report(df, current_bug_id)\n",
    "    inverted_index = build_inverted_index(previous_bugs, 'natural_language')\n",
    "    pre_bug_reports_vector = compute_ltc(previous_bugs, inverted_index, 'natural_language')\n",
    "\n",
    "    current_bug_vector = compute_lnc(df[df.key == current_bug_id].iloc[0], 'natural_language')\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for bug_id, words in pre_bug_reports_vector.items():\n",
    "        dot_product = 0.0\n",
    "        for term in current_bug_vector:\n",
    "            dot_product += current_bug_vector[term] * words.get(term, 0.0)\n",
    "\n",
    "        scores[bug_id] = dot_product\n",
    "\n",
    "    return scores"
   ],
   "id": "d1fda2c35f2f646d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:07:37.764800Z",
     "start_time": "2025-04-10T13:07:37.761540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_related_files(df, similarity_dict):\n",
    "    relevant_bugs = {bug_id: score for bug_id, score in similarity_dict.items()}\n",
    "\n",
    "    if not relevant_bugs:\n",
    "        return {}\n",
    "\n",
    "    file_scores = {}\n",
    "\n",
    "    for bug_id, score in relevant_bugs.items():\n",
    "        files = df[df['key'] == bug_id]['fixed_files'].iloc[0]\n",
    "        for file in files:\n",
    "            if file in file_scores:\n",
    "                file_scores[file].append(score)\n",
    "            else:\n",
    "                file_scores[file] = [score]\n",
    "\n",
    "    average_file_scores = {file: sum(scores) / len(scores) for file, scores in file_scores.items()}\n",
    "\n",
    "    return average_file_scores"
   ],
   "id": "4977bb7a59d71b93",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CO-CHANGE MATRIX",
   "id": "c1a7a5023fc63ada"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:07:41.051246Z",
     "start_time": "2025-04-10T13:07:40.631640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for files in bug_report_dataset['fixed_files'].dropna():\n",
    "    if len(files) < 2:\n",
    "        continue\n",
    "    for i in range(len(files)):\n",
    "        for j in range(i + 1, len(files)):\n",
    "            G.add_edge(files[i], files[j])\n",
    "\n",
    "clusters = list(nx.connected_components(G))\n"
   ],
   "id": "95a1dbee636a3d58",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:07:41.058064Z",
     "start_time": "2025-04-10T13:07:41.054755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_to_cluster = {}\n",
    "for cid, cluster in enumerate(clusters):\n",
    "    for f_name in cluster:\n",
    "        file_to_cluster[f_name] = cid"
   ],
   "id": "bac56cc6dc13b9ea",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FLOW",
   "id": "569f11dd7a1e95f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:07:41.278618Z",
     "start_time": "2025-04-10T13:07:41.275716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_final_score(report, alpha, top_k):\n",
    "    rvsm_score = compute_rank_files_indexing(report, 0.4)\n",
    "\n",
    "    similarity_bug_scores = calculate_bug_query_similarity(bug_report_dataset, report.key)\n",
    "    simi_previous_bugs_score = get_related_files(bug_report_dataset, similarity_bug_scores)\n",
    "\n",
    "    final_score = rvsm_score\n",
    "\n",
    "    for directory in simi_previous_bugs_score:\n",
    "        if directory in final_score:\n",
    "            final_score[directory] = (1 - alpha) * final_score[directory] + alpha * simi_previous_bugs_score[directory]\n",
    "\n",
    "    return dict(sorted(final_score.items(), key=lambda item: item[1], reverse=True)[:top_k])"
   ],
   "id": "a5ffcc6d20e7e5b9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:15:31.512361Z",
     "start_time": "2025-04-10T13:07:41.864296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "list_prediction = {}\n",
    "\n",
    "for idx, bug_report in bug_report_dataset.iterrows():\n",
    "    scores = calculate_final_score(bug_report, 0.2, 100)\n",
    "\n",
    "    boosted_scores = copy.deepcopy(scores)\n",
    "    cluster_scores = defaultdict(list)\n",
    "\n",
    "    for file in scores:\n",
    "        c_id = file_to_cluster.get(file)\n",
    "        if c_id is not None:\n",
    "            cluster_scores[c_id].append(scores[file])\n",
    "\n",
    "    cluster_avg = {cid: np.mean(scores) for cid, scores in cluster_scores.items()}\n",
    "\n",
    "    for file_name in scores:\n",
    "        c_id = file_to_cluster.get(file_name)\n",
    "        if c_id is not None:\n",
    "            boosted_scores[file_name] += 0.3 * cluster_avg[c_id]\n",
    "\n",
    "    list_prediction[bug_report.key] = boosted_scores"
   ],
   "id": "d31358c6fea6a8ad",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## EVALUATE",
   "id": "759ed7ced6a63fb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:15:31.646850Z",
     "start_time": "2025-04-10T13:15:31.643758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_ground_truth():\n",
    "    ground_truth = {}\n",
    "    for report_data in bug_report_dataset.itertuples():\n",
    "        ground_truth[report_data.key] = report_data.fixed_files\n",
    "    return ground_truth"
   ],
   "id": "a348d4224f28af08",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:15:31.656518Z",
     "start_time": "2025-04-10T13:15:31.651902Z"
    }
   },
   "cell_type": "code",
   "source": "ground_truth_data = fetch_ground_truth()",
   "id": "c71628ba4a39a921",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:15:31.776767Z",
     "start_time": "2025-04-10T13:15:31.771753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_k_accuracy(predictions, ground_truth, k=1):\n",
    "    correct = 0\n",
    "    total_queries = len(predictions)\n",
    "\n",
    "    for bug_id in predictions:\n",
    "        temp_prediction = dict(list(predictions[bug_id].items())[:k])\n",
    "        predict_top_k = temp_prediction.keys()\n",
    "        true_directory = ground_truth[bug_id]\n",
    "\n",
    "        if any(doc in true_directory for doc in predict_top_k):\n",
    "            correct += 1\n",
    "\n",
    "    return correct / total_queries if total_queries > 0 else 0\n",
    "\n",
    "def average_precision(predicted, relevant):\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "\n",
    "    relevant_set = set(relevant)\n",
    "    hits = 0\n",
    "    precision_sum = 0.0\n",
    "\n",
    "    for i, (doc_id, _) in enumerate(predicted):\n",
    "        if doc_id in relevant_set:\n",
    "            hits += 1\n",
    "            precision_sum += hits / (i + 1)\n",
    "\n",
    "    return precision_sum / len(relevant) if hits > 0 else 0.0\n",
    "\n",
    "def mean_average_precision(predictions, ground_truth):\n",
    "    ap_scores = []\n",
    "    total_queries = len(predictions)\n",
    "\n",
    "    for query_idx in range(total_queries):\n",
    "        pred_docs = predictions[query_idx]\n",
    "        true_docs = ground_truth[query_idx]\n",
    "        ap = average_precision(pred_docs, true_docs)\n",
    "        ap_scores.append(ap)\n",
    "\n",
    "    return np.mean(ap_scores) if ap_scores else 0.0\n",
    "\n",
    "def mean_reciprocal_rank(predictions, ground_truth):\n",
    "    rr_scores = []\n",
    "    total_queries = len(predictions)\n",
    "\n",
    "    for query_idx in range(total_queries):\n",
    "        pred_docs = [doc_id for doc_id, _ in predictions[query_idx]]\n",
    "        true_docs = set(ground_truth[query_idx])\n",
    "\n",
    "        for rank, doc_id in enumerate(pred_docs, 1):\n",
    "            if doc_id in true_docs:\n",
    "                rr_scores.append(1.0 / rank)\n",
    "                break\n",
    "\n",
    "    return np.mean(rr_scores) if rr_scores else 0.0"
   ],
   "id": "e1984cc04f02a3c6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:15:31.906115Z",
     "start_time": "2025-04-10T13:15:31.886626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tính các chỉ số\n",
    "top1_acc = top_k_accuracy(list_prediction, ground_truth_data, k=1)\n",
    "top5_acc = top_k_accuracy(list_prediction, ground_truth_data, k=5)\n",
    "top10_acc = top_k_accuracy(list_prediction, ground_truth_data, k=10)\n",
    "top20_acc = top_k_accuracy(list_prediction, ground_truth_data, k=20)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc:.4f}\")\n",
    "print(f\"Top-10 Accuracy: {top10_acc:.4f}\")\n",
    "print(f\"Top-20 Accuracy: {top20_acc:.4f}\")"
   ],
   "id": "bd560f76ee93a94a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.1903\n",
      "Top-5 Accuracy: 0.3892\n",
      "Top-10 Accuracy: 0.4972\n",
      "Top-20 Accuracy: 0.6013\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
